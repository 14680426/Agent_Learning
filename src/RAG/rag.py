import os
import sys

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•(src/RAG)
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–srcç›®å½•
src_dir = os.path.dirname(current_dir)
# å°†srcç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

from dotenv import load_dotenv
# åŠ è½½é¡¹ç›®æ ¹ç›®å½•ä¸­çš„.envæ–‡ä»¶
project_root = os.path.dirname(src_dir)
load_dotenv(dotenv_path=os.path.join(project_root, '.env'))

from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
from langchain_core.language_models import BaseLanguageModel
from RAG.query import MultiQueryRAG, AbstractQueryRAG, SingleQueryRAG
from RAG.re_rank.local_cross_encoder import LocalCrossEncoderReranker
from langchain_chroma import Chroma
from langchain_core.embeddings import Embeddings
from RAG.re_rank import LocalCrossEncoderReranker


class RAG:
    """RAGä¸»ç±»ï¼Œæ•´åˆå¤šè§’åº¦æŸ¥è¯¢å’Œäº¤å‰æ’åºåŠŸèƒ½"""
    
    def __init__(self, 
                 vectorstore: Chroma,
                 llm: BaseLanguageModel,
                 embeddings: Embeddings,
                 reranker: LocalCrossEncoderReranker = None):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿ
        
        Args:
            vectorstore: å‘é‡æ•°æ®åº“
            llm: è¯­è¨€æ¨¡å‹
            embeddings: åµŒå…¥æ¨¡å‹
            reranker: é‡æ’åºæ¨¡å‹
        """
        self.vectorstore = vectorstore
        self.llm = llm
        self.embeddings = embeddings
        self.reranker = reranker
        print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def multi_query_retrieve(self, question: str, k: int = 3) -> List[Document]:
        """
        å¤šè§’åº¦æŸ¥è¯¢æ–¹æ³•
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        self.multi_query_retriever = MultiQueryRAG(self.vectorstore, self.llm)

        print("ğŸ”„ æ‰§è¡Œå¤šè§’åº¦æŸ¥è¯¢...")
        docs = self.multi_query_retriever.retrieve(question, k)
        print(f"ğŸ“š å¤šè§’åº¦æŸ¥è¯¢è·å¾— {len(docs)} ä¸ªæ–‡æ¡£")
        return docs
    
    def abstract_query_retrieve(self, question: str, k: int = 3) -> List[Document]:
        """
        æŠ½è±¡åŒ–æŸ¥è¯¢æ–¹æ³•
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        self.abstract_query_retriever = AbstractQueryRAG(self.vectorstore, self.llm)

        print("ğŸ”„ æ‰§è¡ŒæŠ½è±¡åŒ–æŸ¥è¯¢...")
        docs = self.abstract_query_retriever.retrieve(question, k)
        print(f"ğŸ“š æŠ½è±¡åŒ–æŸ¥è¯¢è·å¾— {len(docs)} ä¸ªæ–‡æ¡£")
        return docs
    
    def single_query_retrieve(self, question: str, k: int = 3) -> List[Document]:
        """
        å•è§’åº¦æŸ¥è¯¢æ–¹æ³•
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        self.single_query_retriever = SingleQueryRAG(self.vectorstore, self.llm)

        print("ğŸ”„ æ‰§è¡Œæ™®é€šæŸ¥è¯¢...")

        docs = self.single_query_retriever.retrieve(question, k)
        print(f"ğŸ“š æ™®é€šæŸ¥è¯¢è·å¾— {len(docs)} ä¸ªæ–‡æ¡£")
        return docs

    def similarity_search(self, question: str, k: int = 4) -> List[Document]:
        """
        ç›¸ä¼¼åº¦æœç´¢æ–¹æ³•ï¼ˆå¾…å®ç°ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        # TODO: å®ç°ç›¸ä¼¼åº¦æœç´¢
        pass
    
    def hybrid_search(self, question: str, k: int = 4) -> List[Document]:
        """
        æ··åˆæœç´¢æ–¹æ³•ï¼ˆå¾…å®ç°ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        # TODO: å®ç°æ··åˆæœç´¢
        pass
    
    def cross_encoder_rerank(self, question: str, docs: List[Document], k: int = 5) -> List[Document]:
        """
        äº¤å‰ç¼–ç å™¨é‡æ’åºæ–¹æ³•
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            docs: å¾…æ’åºæ–‡æ¡£åˆ—è¡¨
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        print("âš–ï¸ æ‰§è¡Œäº¤å‰ç¼–ç å™¨é‡æ’åº...")
        reranked_docs = self.reranker.rerank(question, docs, k)
        print(f"âœ… äº¤å‰ç¼–ç å™¨é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_docs)} ä¸ªæœ€ç›¸å…³æ–‡æ¡£")
        return reranked_docs
    
    def diversity_rerank(self, question: str, docs: List[Document], k: int = 5) -> List[Document]:
        """
        å¤šæ ·æ€§é‡æ’åºæ–¹æ³•ï¼ˆå¾…å®ç°ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            docs: å¾…æ’åºæ–‡æ¡£åˆ—è¡¨
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        # TODO: å®ç°å¤šæ ·æ€§é‡æ’åº
        pass
    
    def reciprocal_rank_fusion(self, question: str, docs_list: List[List[Document]], k: int = 5) -> List[Document]:
        """
        reciprocal rank fusionæ’åºæ–¹æ³•ï¼ˆå¾…å®ç°ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            docs_list: å¤šä¸ªæ£€ç´¢å™¨è¿”å›çš„æ–‡æ¡£åˆ—è¡¨
            k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            èåˆæ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        # TODO: å®ç°reciprocal rank fusionæ’åº
        pass
    
    def query(self, question: str, initial_k: int = 20, final_k: int = 5) -> Dict[str, Any]:
        """
        æ‰§è¡ŒRAGæŸ¥è¯¢ï¼šå¤šè§’åº¦æŸ¥è¯¢ + é‡æ’åº
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            initial_k: åˆå§‹æ£€ç´¢æ–‡æ¡£æ•°
            final_k: æœ€ç»ˆè¿”å›æ–‡æ¡£æ•°
            
        Returns:
            åŒ…å«æ£€ç´¢åˆ°çš„æ–‡æ¡£çš„ç»“æœå­—å…¸
        """
        # ä½¿ç”¨LLMåˆ†æé—®é¢˜å¹¶å†³å®šæœ€é€‚åˆçš„æŸ¥è¯¢æ–¹å¼
        queries = self._determine_query_strategy(question)
        print(f"ğŸ” å¼€å§‹å¤„ç†é—®é¢˜: {question}")
        print(f"ğŸ” é€‰æ‹©çš„æŸ¥è¯¢ç­–ç•¥: {queries}")
        
        # 1. æŸ¥è¯¢
        if queries == "abstract":
            queries_docs = self.abstract_query_retrieve(question, initial_k)
        elif queries == "multi":
            queries_docs = self.multi_query_retrieve(question, initial_k)
        elif queries == "single":
            queries_docs = self.single_query_retrieve(question, initial_k)
        else:
            print("æ— æ•ˆçš„æŸ¥è¯¢æ–¹å¼")
            return {"documents": []}
        
        # 2. é‡æ’åº
        print(f"ğŸ”„ å¯¹ {len(queries_docs)} ä¸ªæ–‡æ¡£è¿›è¡Œé‡æ’åº...")
        reranked_docs = self.cross_encoder_rerank(question, queries_docs, final_k)
        print(f"âœ… é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_docs)} ä¸ªæ–‡æ¡£")
        
        return {
            "documents": reranked_docs,
            "query_strategy": queries
        }
    
    def _determine_query_strategy(self, question: str) -> str:
        """
        ä½¿ç”¨LLMåˆ†æé—®é¢˜å¹¶å†³å®šæœ€é€‚åˆçš„æŸ¥è¯¢ç­–ç•¥
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            æŸ¥è¯¢ç­–ç•¥ ("single", "multi", "abstract")
        """
        # å®šä¹‰æç¤ºæ¨¡æ¿
        prompt_template = """
            ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æŸ¥è¯¢ç­–ç•¥é€‰æ‹©åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œé€‰æ‹©æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥ï¼š

            ç­–ç•¥è¯´æ˜ï¼š
            1. singleï¼ˆå•æŸ¥è¯¢ï¼‰ï¼šé€‚ç”¨äºå…·ä½“ã€æ˜ç¡®çš„é—®é¢˜ï¼Œæ¶‰åŠä¸¤ä¸ªåŠä»¥ä¸Šçš„è¯è¯­ä¹‹é—´çš„å…³ç³»ï¼Œå¦‚"æ»‘åŠ¨æ£€æµ‹æœ‰ä»€ä¹ˆå¸¸ç”¨çš„æ–¹æ³•ï¼Ÿ"
            2. multiï¼ˆå¤šè§’åº¦æŸ¥è¯¢ï¼‰ï¼šé€‚ç”¨äºéœ€è¦ä»å¤šä¸ªè§’åº¦ç†è§£çš„é—®é¢˜ï¼Œå¦‚"æ»‘åŠ¨æ£€æµ‹çš„åŸç†å’Œåº”ç”¨ï¼Ÿ"
            3. abstractï¼ˆæŠ½è±¡æŸ¥è¯¢ï¼‰ï¼šé€‚ç”¨äºé—®é¢˜ç»™å‡ºçš„ä¿¡æ¯æ¯”è¾ƒå°‘ï¼Œåªæœ‰æ¶‰åŠä¸€ä¸ªè¯è¯­ï¼Œå¦‚"æ»‘åŠ¨æ£€æµ‹æ˜¯ä»€ä¹ˆï¼Ÿ"

            è¯·åˆ†æä»¥ä¸‹é—®é¢˜å¹¶é€‰æ‹©æœ€é€‚åˆçš„ç­–ç•¥ï¼Œåªéœ€å›å¤ç­–ç•¥åç§°ï¼ˆsingle/multi/abstractï¼‰ï¼š

            é—®é¢˜ï¼š{question}

            ç­–ç•¥ï¼š
            """.strip()
        
        # æ„å»ºæç¤º
        prompt = prompt_template.format(question=question)
        
        try:
            # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
            response = self.llm.invoke(prompt)
            strategy = response.content.strip().lower()
            
            # éªŒè¯ç­–ç•¥æœ‰æ•ˆæ€§
            if strategy in ["single", "multi", "abstract"]:
                return strategy
            else:
                # é»˜è®¤ä½¿ç”¨å¤šè§’åº¦æŸ¥è¯¢
                print("æ— æ•ˆçš„æŸ¥è¯¢æ–¹å¼ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
                return "multi"
        except Exception as e:
            print(f"âš ï¸  ç­–ç•¥é€‰æ‹©å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
            # é»˜è®¤ä½¿ç”¨å¤šè§’åº¦æŸ¥è¯¢
            return "multi"

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºRAGç³»ç»Ÿçš„ä½¿ç”¨"""
    print("=" * 50)
    print("RAGç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    import os
    from Models import ModelManager
    modelManager = ModelManager()
    llm = modelManager.get_qwen_model()

    # åµŒå…¥æ¨¡å‹è·¯å¾„
    embedding_model_path = "./Models/maidalun/bce-embedding-base_v1"
    
    # æ£€æŸ¥åµŒå…¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(embedding_model_path) or not os.listdir(embedding_model_path):
        raise ValueError(f"åµŒå…¥æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸ºç©º: {embedding_model_path}ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šè·¯å¾„ã€‚")

    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆå¯ç”¨ GPUï¼‰
    from langchain_community.embeddings import HuggingFaceEmbeddings
    embeddings = HuggingFaceEmbeddings(
        model_name=embedding_model_path,
        model_kwargs={"device": "cuda"},               # ä½¿ç”¨ GPU åŠ é€Ÿ
        encode_kwargs={"normalize_embeddings": True}   # å½’ä¸€åŒ–ä¾¿äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    )

    # åŠ è½½Chromaå‘é‡æ•°æ®åº“ï¼ŒæŒ‡å®šé›†åˆåç§°
    chroma_persist_directory = "./RAG/tools/chroma_db"
    from langchain_community.vectorstores import Chroma
    vectorstore = Chroma(
        persist_directory=chroma_persist_directory,
        embedding_function=embeddings,
        collection_name="local_pdf_chunks"  # æŒ‡å®šé»˜è®¤é›†åˆåç§°
    )

    cross_encoder_model_path = "./Models/ms-marco-MiniLM-L-6-v2/cross-encoder"
    
    # æ£€æŸ¥äº¤å‰ç¼–ç å™¨æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(cross_encoder_model_path) or not os.listdir(cross_encoder_model_path):
        raise ValueError(f"äº¤å‰ç¼–ç å™¨æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸ºç©º: {cross_encoder_model_path}ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šè·¯å¾„ã€‚")

    # åˆ›å»ºRAGå¯¹è±¡
    print("\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    from RAG.re_rank.local_cross_encoder import LocalCrossEncoderReranker
    reranker = LocalCrossEncoderReranker(embeddings=embeddings, model_path=cross_encoder_model_path)
    rag = RAG(llm=llm, embeddings=embeddings, vectorstore=vectorstore, reranker=reranker)
    print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    # æ‰§è¡ŒæŸ¥è¯¢
    question = "ä»€ä¹ˆæ˜¯æ»‘åŠ¨æ£€æµ‹ï¼Ÿ"
    print(f"\nğŸ” æŸ¥è¯¢é—®é¢˜: {question}")
    
    try:
        result = rag.query(question)
        print(f"\nğŸ“Š ç›¸å…³æ–‡æ¡£æ•°é‡: {len(result['documents'])}")
        
        # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£ç‰‡æ®µ
        print("\nğŸ“„ ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
        for i, doc in enumerate(result['documents']):
            print(f"\n[{i+1}] {doc.page_content[:200]}...")
            
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()